# paper list 
## 阅读理解    
![MRC_概览](./../../Record-logger/图片/00045_MRC整理总览_ZT.png)  
![MRC_示意图](./../../Record-Logger/图片/00044_MRC背景总结_ZT.png)  
![MRC_数据集](./../../Record-Logger/图片/00043_MRC数据集整理_ZT.png)  
## Bert @ Pre-Trained  

## MRC综述: 
* 陈丹绮博士论文: 
  * 论文地址:   
  *  别人笔记: 
  * 自己笔记: 
* 王炳宁博士论文:
  * 论文地址: 
  * 自己笔记:  
* 吴明昊博士论文:
  * 论文地址: 
  * 自己笔记:   
* 国防科大综述:
  * 论文地址: 
  * 笔记:  
* UCAS综述:
  * 论文地址: 
  * 笔记:  
* 推理综述:
  * 论文地址: 
  * 笔记:   

### 数据集系列文章: 
* 2013-MCTest : 
  * 论文地址: 
  * 笔记: 
  *  
* 2015-CNN/Daily Mail：
* 2016-SQuAD ：   

## GNN  

## Bert-预训练  

## 其他任务   
## 大的实验室: 
1. UCL MRC_Group: 
2. AI2: 
3. 微软:
4. THU:
5. PKU:

## **数据集文章**    
### MRC
1. **ROPES** |  Reasoning Over Paragraph Effects in Situations  
   * arXiv: https://arxiv.org/abs/1908.05852 
   * Leadboard: https://leaderboard.allenai.org/ropes
   * Note
   * Label: EMNLP2019 
2. .CommonSenseQA |COMMONSENSEQA: A Question Answering Challenge Targeting Commonsense Knowledge | 
   * arXiv: https://arxiv.org/pdf/1811.00937.pdf |  
   * Leadboard: https://www.tau-nlp.org/csqa-leaderboard 
   * Note:
   * Label: 2018 
3. CoQA |  CoQA: A Conversational Question Answering Challenge 
   * arXiv: https://arxiv.org/pdf/1808.07042.pdf 
   * Leadboard:https://stanfordnlp.github.io/coqa/ 
   * Note:
   * Label: 2018 
4. MultiRC | Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences
    * ACL: https://www.aclweb.org/anthology/N18-1023/   
   * Leadboard: https://cogcomp.seas.upenn.edu/multirc/ 
    * Note: 
    * Label: NAACL2018 
5. OpenBookQA | Can a Suit of Armor Conduct Electricity?  A New Dataset for Open Book Question Answering
   * arXiv: https://arxiv.org/pdf/1809.02789.pdf  
   * Leadboard: 
   * Note:
   * Label: 201809
6. RACE  |  RACE: Large-scale ReAding Comprehension Dataset From Examinations
   * arXiv: https://arxiv.org/pdf/1704.04683.pdf 
   * Leadboard: http://www.qizhexie.com//data/RACE_leaderboard 
   * Note:
   * Label: 201809
7. XCMRC  |  XCMRC: Evaluating Cross-lingual Machine Reading Comprehension

      * arXiv: https://arxiv.org/pdf/1908.05416.pdf 
   * Leadboard/baseline: https://github.com/NLPBLCU/XCMRC
   * Note:
   * Label: 跨语言 | 20190825  
8. CLMRC  |  Cross-Lingual Machine Reading Comprehension 
    * arXiv: https://arxiv.org/pdf/1909.00361.pdf 
   * Leadboard/baseline: https://github.com/ymcui/Cross-Lingual-MRC
   * Note:
   * Label: 跨语言 
9.  WINOGRANDE  |  WINOGRANDE: An Adversarial Winograd Schema Challenge at Scale  
    * arXiv: https://arxiv.org/pdf/1907.10641.pdf
    * Leadboard: 
    * Note:
    * Label:  201911 
11. HellaSwag  |  HellaSwag: Can a Machine Really Finish Your Sentence?  
    * arXiv: https://arxiv.org/pdf/1905.07830.pdf    
    * Leadboard: https://rowanzellers.com/hellaswag/  
    * Note:
    * Label:  201905  
12. McTaco  |  “Going on a vacation” takes longer than “Going for a walk”: A Study of Temporal Commonsense Understanding

    * arXiv: https://arxiv.org/pdf/1909.03065.pdf
    * Leadboard: https://leaderboard.allenai.org/mctaco/submissions/public 
    * Note:
    * Label:  EMNLP2019 | ai2
13. Social IQA  | SOCIAL IQA: Commonsense Reasoning about Social Interactions    
    * arXiv: https://arxiv.org/pdf/1904.09728.pdf 
    * Leadboard: https://leaderboard.allenai.org/socialiqa/submissions/public
    * Note:
    * Label:  2019 
14. CosMosQA  |  Cosmos QA : Machine Reading Comprehension with Contextual Commonsense  Reasoning (EMNLP'2019)   
    * arXiv: https://arxiv.org/pdf/1909.00277.pdf
    * Leadboard: https://wilburone.github.io/cosmos/
    * Note:
    * Label: emnlp2019 
15. PubMedQA |  PubMedQA : A Dataset for Biomedical Research Question Answering
    * arXiv: https://arxiv.org/pdf/1909.06146.pdf  
    * Leadboard: https://pubmedqa.github.io 
    * Note:
    * Label: 2019009  
16. GeoQA  | GeoSQA: A Benchmark for Scenario-based Question Answering in the Geography   Domain at High School Level   
    * arXiv: https://arxiv.org/pdf/1908.07855.pdf  
    * Leadboard: 
    * Note:
    * Label:  emnlp2019 
17.  HEAD-QA |  HEAD-QA: A Healthcare Dataset for Complex Reasoning
     * arXiv: https://arxiv.org/abs/1906.04701 
     * Leadboard: 
     * Note:
     * Label: 2019  
18. ReCoRD | ReCoRD: Bridging the Gap between Human and Machine Commonsense Reading Comprehension  
    * arXiv: https://arxiv.org/pdf/1810.12885.pdf  
    * Leadboard: https://sheng-z.github.io/ReCoRD-explorer/  
    * Note:
    * Label: 2018     
19. c^3 |  Investigating Prior Knowledge for Challenging Chinese Machine Reading Comprehension 
    * arXiv: https://arxiv.org/pdf/1904.09679.pdf
    * Leadboard/Baseline : https://dataset.org/c3/  |   https://github.com/AutoAVE/c3  
    * Note:
    * Label:  2019 | 腾讯、Cornell、UW、AI2 
20. Dream |  DREAM: A Challenge Dataset and Models for Dialogue-Based Reading Comprehension
    * arXiv: https://arxiv.org/pdf/1902.00164.pdf 
    * Leadboard: https://dataset.org/dream/
    * Note:
    * Label:2019 | 腾讯、Cornell、UW、AI2 
21. QAngaroo 、WikihopQA |   Constructing Datasets for Multi-hop Reading Comprehension  Across Documents

    * arXiv: https://arxiv.org/pdf/1710.06481v1.pdf  
    * Leadboard: http://qangaroo.cs.ucl.ac.uk/  
    * Note:
    * Label: Multi-hop 
22. JEC-QA | JEC-QA: A Legal-Domain Question Answering Dataset  
    * arXiv: https://arxiv.org/pdf/1911.12011.pdf
    * Leadboard/baseline: http://jecqa.thunlp.org/ 
    * Note:
    * Label:
23. PIQA | PIQA: Reasoning about Physical Commonsense in Natural Language   
    * arXiv: https://arxiv.org/pdf/1911.11641.pdf  
    * Leadboard: https://yonatanbisk.com/piqa/
    * Note:
    * Label:
24. TweetQA | TWEETQA: A Social Media Focused Question Answering Dataset  
    * arXiv: https://arxiv.org/pdf/1907.06292.pdf
    * Leadboard: https://tweetqa.github.io/
    * Note:
    * Label:
25. RC-QED | RC-QED: Evaluating Natural Language Derivations in Multi-Hop Reading Comprehension   
    * arXiv: https://arxiv.org/pdf/1910.04601.pdf 
    * Leadboard/baseline/data:https://naoya-i.github.io/rc-qed/  
    * Note:
    * Label:
26. MLQA | MLQA: Evaluating Cross-lingual Extractive Question Answering  
    * arXiv: https://arxiv.org/pdf/1910.07475.pdf 
    * Leadboard/baseline:https://github.com/facebookresearch/MLQA  
    * Note:
    * Label: 跨语言 
27. QuAC| QuAC : Question Answering in Context  
    * arXiv: https://arxiv.org/pdf/1808.07036.pdf
    * Leadboard: http://quac.ai/
    * Note:
    * Label:
28. CNN/Daily-Mail  |  Challenging Reading Comprehension on Daily Conversation: Passage Completion on Multiparty Dialog  
    * arXiv/acl:https://www.aclweb.org/anthology/N18-1185/  
    * Leadboard/baseline:https://github.com/danqi/rc-cnn-dailymail  
    * Note:
    * Label:
29. 谷歌acl2019医疗对话数据集| Extracting Symptoms and their Status from Clinical Conversations   
    * arXiv:https://arxiv.org/pdf/1906.02239.pdf  
    * Leadboard: 未开源
    * Note:
    * Label:
30. NAACL2019医患对话数据集  | Fast Prototyping a Dialogue Comprehension System for Nurse-Patient Conversations on Symptom Monitoring
  
    * arXiv: https://arxiv.org/pdf/1903.03530.pdf
    * Leadboard: 未开源
    * Note:
    * Label:
31. DROP |  DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs  
    * arXiv: https://arxiv.org/pdf/1903.00161v1.pdf
    * Leadboard: https://leaderboard.allenai.org/drop/submissions/public
    * Note:
    * Label:
32. HotpotQA | HOTPOTQA: A Dataset for Diverse, Explainable Multi-hop Question Answering
    * arXiv: https://arxiv.org/pdf/1809.09600.pdf
    * Leadboard: https://hotpotqa.github.io/ 
    * Note:
    * Label:
33. QuoRef | QUOREF: A Reading Comprehension Dataset with Questions Requiring Coreferential Reasoning
    * arXiv: https://arxiv.org/pdf/1908.05803.pdf 
    * Leadboard: https://leaderboard.allenai.org/quoref/submissions/public 
    * Note:
    * Label:

34. Multi-QA | MULTIQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension 
    * arXiv: https://arxiv.org/pdf/1905.13453.pdf
    * Leadboard: 
    * Note:
    * Label: 多个数据集合成
35. MRQA2019| MRQA 2019 Shared Task: Evaluating Generalization in Reading Comprehension
    * arXiv: https://arxiv.org/pdf/1910.09753.pdf 
    * Leadboard/baseline: https://github.com/mrqa/MRQA-Shared-Task-2019  
    * Note:
    * Label:多个数据集合成
36. ATOMIC | ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning 
    * arXiv: https://homes.cs.washington.edu/~msap/atomic/data/sap2019atomic.pdf  
    * Leadboard/data: https://homes.cs.washington.edu/˜msap/atomic/.
    * Note:
    * Label:外部知识库 数据集 
37. ORB | ORB: An Open Reading Benchmark for Comprehensive Evaluation of Machine Reading Comprehension
    * arXiv: https://arxiv.org/abs/1912.12598
    * Leadboard: https://leaderboard.allenai.org/orb/submissions/public 
    * Note:
    * Label: 多数据集合成 
38. ACL2019做对话同时发布数据集| Conversing by Reading: Contentful Neural Conversation with On-demand Machine Reading
    * arXiv/ACL: https://www.aclweb.org/anthology/P19-1539.pdf
    * Leadboard/baseline: https://github.com/qkaren/converse_reading_cmr
    * Note:
    * Label:Wikipedia文章+Reddit对话 --> 数据集 | ACL2019 | 数据集
39. emrQA | emrQA: A Large Corpus for Question Answering on Electronic Medical Records 
    * arXiv: https://arxiv.org/pdf/1809.00732.pdf
    * Leadboard/Baseline: https://github.com/panushri25/emrQA
    * Note:
    * Label:
40. ComQA | ComQA: A Community-sourced Dataset for Complex Factoid Question Answering with Paraphrase Clusters
    * arXiv: https://arxiv.org/abs/1809.09528
    * Leadboard: 
    * Note:
    * Label:社区问答数据集
41. ConvQuestions |  Look before you Hop: Conversational Question Answering over Knowledge Graphs Using Judicious Context Expansion
    * arXiv: https://arxiv.org/pdf/1910.03262.pdf
    * Leadboard: http://qa.mpi-inf.mpg.de/convex/  
    * Note:
    * Label: cikm2019 
42. ShARC(Shaping Answers with Rules through Conversation) |  Interpretation of Natural Language Rules in Conversational Machine Reading
    * arXiv: https://arxiv.org/pdf/1809.01494.pdf 
    * Leadboard: https://sharc-data.github.io/  
    * Note:
    * Label: UCL_MRC_Grouping |  
43. DuoRC | DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension
    * arXiv: https://arxiv.org/pdf/1804.07927.pdf 
    * Leadboard: https://duorc.github.io/  
    * Note:
    * Label: 2018    
44. MCScript|  MCScript: A Novel Dataset for Assessing Machine Comprehension Using Script Knowledge 
    * arXiv:https://arxiv.org/abs/1803.05223
    * Leadboard:  
    * Note:  
    * Label: 
45. SQuAD2.0 | Know What You Don’t Know: Unanswerable Questions for SQuAD 
    * arXiv: https://arxiv.org/pdf/1806.03822.pdf  
    * Leadboard:https://rajpurkar.github.io/SQuAD-explorer/    
    * Note:  
    * Label: 
46. RecipeQA |  RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes 
    * arXiv:https://arxiv.org/pdf/1809.00812.pdf 
    * Leadboard:  https://hucvl.github.io/recipeqa/  
    * Note:  
    * Label: 
47. SWAG |  SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference 
    * arXiv: https://arxiv.org/abs/1808.05326
    * Leadboard: https://leaderboard.allenai.org/swag/submissions/public 
    * Note:  
    * Label: 
48. TextWordsQA | Multi-Relational Question Answering from Narratives: Machine Reading and Reasoning in Simulated Worlds   
    * arXiv/ACL:https://www.aclweb.org/anthology/P18-1077.pdf
    * Leadboard:  https://igorlabutov.github.io/textworldsqa.github.io/  
    * Note:  
    * Label: 
49. CLOTH | Large-scale Cloze Test Dataset Created by Teachers  
    * arXiv: https://arxiv.org/abs/1711.03225
    * Leadboard: http://www.qizhexie.com/data/CLOTH_leaderboard.html
    * Note:  
    * Label: 2017 
50. CLiCR  | CliCR: A Dataset of Clinical Case Reports for Machine Reading Comprehension
    * arXiv: https://arxiv.org/abs/1803.09720
    * Leadboard/Baseline: https://github.com/clips/clicr 
    * Note:  
    * Label: 2018 
51. DuReader | DuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications 
    * arXiv:https://arxiv.org/abs/1711.05073 
    * Leadboard/baseline:https://github.com/baidu/DuReader    
    * Note:  
    * Label: 中文 2017 
52. NarrativeQA | The NarrativeQA Reading Comprehension Challenge    
    * arXiv:https://arxiv.org/abs/1712.07040 
    * Leadboard:  
    * Note:  
    * Label: google 2017 
53. Who did What | Who did What: A Large-Scale Person-Centered Cloze Dataset
    * arXiv: https://arxiv.org/abs/1608.05457 
    * Leadboard:  https://tticnlp.github.io/who_did_what/leaderBoard.html  
    * Note:  
    * Label: 2017 
54. SearchQA | SearchQA: A New Q&A Dataset
Augmented with Context from a Search Engine  
    * arXiv: https://arxiv.org/pdf/1704.05179.pdf  
    * Leadboard/baseline: https://github.com/nyu-dl/dl4ir-searchqA   
    * Note:  
    * Label: 2017  
45. TriviaQA | TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension  
    * arXiv:https://arxiv.org/abs/1705.03551 
    * Leadboard/baseline:  http://nlp.cs.washington.edu/triviaqa/  
    * Note:  
    * Label: 2017
50. Quasar| Quasar: Datasets for Question Answering by Search and Reading    
    * arXiv:https://arxiv.org/abs/1707.03904 
    * Leadboard/baseline: https://github.com/bdhingra/quasar   
    * Note:  
    * Label: 2017 
50. bAbi |  TOWARDS AI-COMPLETE QUESTION ANSWERING: A SET OF PREREQUISITE TOY TASKS
    * arXiv:https://arxiv.org/pdf/1502.05698.pdf
    * Leadboard:  https://github.com/facebook/bAbI-tasks 
    * Note: CBT
    * Label: 2015 
50. CBT(Children's Books Tests) | The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations  
    * arXiv:https://arxiv.org/abs/1511.02301 
    * Leadboard:  
    * Note:  
    * Label: bAbi 
50. MS_MARCO | MS MARCO: A Human Generated MAchine Reading COmprehension Dataset
    * arXiv:https://arxiv.org/pdf/1611.09268.pdf 
    * Leadboard:  http://www.msmarco.org/leaders.aspx 
    * Note:  
    * Label: 2018 
50. NewsQA | NewsQA: A Machine Comprehension Dataset
    * arXiv:https://arxiv.org/abs/1611.09830 
    * Leadboard: https://www.microsoft.com/en-us/research/project/newsqa-dataset/  
    * Note:  
    * Label: 2017 
50. LAMBADA | The LAMBADA dataset: Word prediction requiring a broad discourse context
    * arXiv: https://arxiv.org/abs/1606.06031 
    * Leadboard:  
    * Note:  
    * Label: 2016 
50. SCT(Story Cloze Test) |  A Corpus and Evaluation Framework for Deeper Understanding of Commonsense Stories  
    * arXiv:https://arxiv.org/abs/1604.01696 
    * Leadboard/Baseline: https://www.cs.rochester.edu/nlp/rocstories/ 
    * Note:  
    * Label: 
50. CMRC |   
    * arXiv/地址: http://www.lrec-conf.org/proceedings/lrec2018/pdf/32.pdf 
    * Leadboard:  
    * Note:  
    * Label:中文、哈工大-科大讯飞 
50. ROCStories：A Corpus and Evaluation Framework for Deeper Understanding of Commonsense Stories   
    * arXiv:https://arxiv.org/abs/1604.01696?context=cs.AI 
    * Leadboard: https://cs.rochester.edu/nlp/rocstories/ 
    * Note:日常生活故事的语料库，包含大量事件之间的因果和时间关系，是学习常识的理想选择  
    * Label:2016 | 微软 |  
50. SherLIiC：SherLIiC: A Typed Event-Focused Lexical Inference Benchmark for Evaluating Natural Language Inference    
    * arXiv:https://arxiv.org/pdf/1906.01393v1.pdf 
    * Leadboard:https://github.com/mnschmit/SherLIiC  
    * Note:  
    * Label: 
50. AlphaNLI：ABDUCTIVE COMMONSENSE REASONING    
   * arXiv:https://arxiv.org/pdf/1908.05739.pdf   
   * Repo:  
    * Leadboard: https://leaderboard.allenai.org/anli/submissions/get-started  
    * Sum: 诱导推理:给定2个上下文，然后给定选择题，选择正确的。  
    * Note:  
    * Label: pass 
51. Story Commonsense： Modeling Naive Psychology of Characters in Simple Commonsense Stories   
    * arXiv:https://www.aclweb.org/anthology/P18-1213.pdf 
    * Leadboard:  https://uwnlp.github.io/storycommonsense/ 
    * Note:  
    * Label:  
52. ARCT: The Argument Reasoning Comprehension Task: Identification and Reconstruction of Implicit Warrants   
    * arXiv:https://arxiv.org/abs/1708.01425 
    * Leadboard:   https://github.com/UKPLab/argumentreasoning-comprehension-task
    * Note:  
    * Label: naac2018 
53. ARC: AI2 Reasoning Challenge (ARC)     
    * arXiv:https://arxiv.org/pdf/1803.05457.pdf
    * Leadboard:  https://data.allenai.org/arc/
    * Note:  
    * Label: 
54. ProPara | Tracking State Changes in Procedural Text: A Challenge Dataset and Models for Process Paragraph Comprehension   
    * arXiv:https://arxiv.org/abs/1805.06975
    * Leadboard:  https://data.allenai.org/propara/    http://data.allenai.org/propara/#leaderboard
    * Note:  
    * Label: 
55. Triangle-COPA |   
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
56. SciTail | SCITAIL: A Textual Entailment Dataset from Science Question Answering 
    * arXiv:https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17368/16067 
    * Leadboard: http://data.allenai.org/scitail
    * Note:  
    * Label: 
57. OCI数据集-NLI常识推理| Ordinal Common-sense Inference
    * arXiv:https://arxiv.org/pdf/1611.00601.pdf 
    * Leadboard:  : http://decomp.net/
    * Note:  
    * Label: NLI | jhu | 
58. CEAC| Emotion Action Detection and Emotion Inference: the Task and Dataset   
    * arXiv: https://arxiv.org/pdf/1903.06901.pdf 
    * Leadboard:  
    * Note:  
    * Label:情绪和事件结合，情绪推理，情绪动作检测 |  中文 
59. ASQ | Asking the Right Question: Inferring Advice-Seeking Intentions from Personal Narratives   
    * arXiv:https://arxiv.org/pdf/1904.01587.pdf
    * Leadboard: t https://github.com/CornellNLP/ASQ 
    * Note:
    * 给定一段叙述，检测 个人叙述中推断寻求建议的意图。  二选1: 文章的意图是询问什么呢？   
    * Label:Cornell大学  
60. ARC数据集 | Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge   
    * arXiv:https://arxiv.org/pdf/1803.05457.pdf
    * Leadboard: http://data.allenai.org/arc 
    * Note:  
    * Sum: 常识推理，问答形式，没有文章和 |  Q:矿物的哪一种属性直接可以通过观察得到？  A:色泽 B:质量 C:重量 D:硬度 
    * Label: AI2 | 常识推理
61. 论据推理任务| The Argument Reasoning Comprehension Task:Identification and Reconstruction of Implicit Warrants  
    * arXiv:https://arxiv.org/pdf/1708.01425.pdf
    * Leadboard:  https://github.com/UKPLab/argument-reasoning-comprehension-task
    * Note:  
    * Sum: 给定 2个 保证(论证) + 1个 Reason过程 + 1个 结论Claim --> R+ 1/2 w --> Claim过程: 
    * R：美国小姐给与 奖学金;  Claim： 美国小姐对女性是好的;  W0[正确]: 奖学金给女性机会去学习  W1:奖学金使女性离开家
    * Label: 
62. Modeling Naive Psychology of Characters in Simple Commonsense Stories   
    * arXiv:https://www.aclweb.org/anthology/P18-1213.pdf
    * Leadboard:https://uwnlp.github.io/storycommonsense/
    * Note:  
    * Sum: 故事中的  情绪变化跟踪任务，需要常识进行解决。 
    * Label: AI2 | ACL20118 | 没意义
63. SP-10K: A Large-scale Evaluation Set for Selectional Preference Acquisition 
    * arXiv:https://arxiv.org/pdf/1906.02123.pdf  
    * Leadboard: : https://github.com/HKUST-KnowComp/SP-10K 
    * Note:  
    * Sum： 对于 美国英语中 常见的 动词、名词、形容词 进行常识推理的数据集或者知识库。 
    * Label: 港科 | 20190314 | 
63. SC   
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
63. SC   
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
63. SC   
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
63. SC   
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
63. SC   
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
63. SC   
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
63. SC   
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
63. SC   
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
63. SC   
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
63. SC   
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
63. SC   
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
63. SC   
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
63. SC   
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
63. SC   
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
63. SC   
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
### 模型文章 ---QA & MRC    
1. BiDAF | 
    * arXiv:
    * Repo:
    * Note:
    * Label:   
2. QANet |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. EPAr | Explore, Propose, and Assemble: An Interpretable Model for Multi-Hop Reading Comprehension   
    * arXiv:https://arxiv.org/pdf/1906.05210.pdf
    * Repo:https://github.com/jiangycTarheel/EPAr 
    * Note:
    * Label: 
2. model | Using Local Knowledge Graph Construction to Scale Seq2Seq Models to Multi-Document Inputs
  
    * arXiv:https://arxiv.org/pdf/1910.08435.pdf 
    * Repo:
    * Sum： 对于 每个问题生成 局部的知识图 
    * Note:
    * Label: 
2. model |  Self-Assembling Modular Networks for Interpretable Multi-Hop Reasoning 
    * arXiv:https://arxiv.org/pdf/1909.05803.pdf
    * Repo:https://github.com/jiangycTarheel/NMN-MultiHopQA
    * Note:
    * Sum: 
    * Label: HotpotQA | 
2. DFGN | Dynamically Fused Graph Network for Multi-hop Reasoning 
    * arXiv:https://www.aclweb.org/anthology/P19-1617.pdf
    * Repo: https://github.com/woshiyyya/DFGN-pytorch
    * Sum: 
    * Note:
    * Label: HotpotQA | acl2019 | 
2. model | Improving the Robustness of Deep Reading Comprehension Models by Leveraging Syntax Prior
  
    * arXiv:https://www.aclweb.org/anthology/D19-5807.pdf
    * Repo:
    * Sum: 利用 语言中的 先验知识增强 MRC中模型的鲁棒性等 
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
2. model |   
    * arXiv:
    * Repo:
    * Note:
    * Label: 
###  模型 & 分析 --Bert @ Pre-Trained Model ans Analyze 
1. Bert |  
    * arXiv:  
    * Repo:
    * Note:
    * Label: 
2. ALBert |  ALBERT: A LITE BERT FOR SELF-SUPERVISED
LEARNING OF LANGUAGE REPRESENTATIONS 
    * arXiv:  https://openreview.net/pdf?id=H1eA7AEtvS 
    * Repo:
    * Note:
    * Label: 
3. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
4. Bert |  Commonsense Knowledge Mining from Pretrained Models 
    * arXiv:https://arxiv.org/pdf/1909.00505.pdf
    * Repo:  
    * Sum: 
    * Note:
    * Label: 
5. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
6. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
7. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
8. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
9. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
10. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
11. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
12. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
13. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
14. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 


### MRC_分析_对抗_总结_和人比较 


### 知识、常识推理       
* 主要关注: allenai、AI2 、 UCL 、阿里、腾讯、百度、THU、PKU、中科院、华盛顿、MIT、UIUC、斯坦福
    
1. SG-Net | SG-Net: Syntax-Guided Machine Reading Comprehension    
   * arXiv: https://arxiv.org/pdf/1908.05147.pdf   
   * Repo:  
   * Sum:通过语言语法知识指导 bert之后的attention计算mask矩阵。   
   * Note:
   * Label: 上交 | 20191120 
2. GapQA  |  What’s Missing: A Knowledge Gap Guided Approach for Multi-hop Question Answering  
   * arXiv: https://arxiv.org/pdf/1909.09253.pdf  
   * Repo: https://github.com/allenai/missing-fact  
   * Sum: 定义了 knowledge_gap 这个概念，并常识去 填补 
   * Note:
   * Label:allenai.org  |  OpenBookQA  |   AAAI2020  |   
3. Kagnet | KagNet: Knowledge-Aware Graph Networks for Commonsense Reasoning  
   * arXiv: https://arxiv.org/pdf/1909.02151.pdf
   * Repo: https://github.com/INK-USC/KagNet   
   * Sum: 
   * Note: 
   * Label: 上交-南加州 | 20190904  | concept--> CommonsenseQA  | 
4. AMS | Align, Mask and Select: A Simple Method for Incorporating Commonsense Knowledge into Language Representation Models  
   * arXiv: https://arxiv.org/pdf/1908.06725.pdf  
   * Repo:  
   * Sum: 
   * Note:
   * Label:阿里-中科院  |  20191112  | CommonsenseQA --Winograd Schema Challenge  |   
5. Incorporating Relation Knowledge into Commonsense Reading Comprehension with Multi-task Learning
   * arXiv: https://arxiv.org/pdf/1908.04530.pdf  
   * Repo:  
   * Sum: 
   * Note:
   * Label: 达摩院 | 20190905  | SemEval-2018 Task 11 and the Cloze Story Test
6. | Incorporating Structured Commonsense Knowledge in Story Completion   
   * arXiv: https://arxiv.org/pdf/1811.00625.pdf   
   * Repo:  
   * Sum: 
   * Note:
   * Label: 20181101 | ROCStory Cloze Task | 腾讯AI-Lab * 南加州  |  
7. KEAG | Incorporating External Knowledge into Machine Reading for Generative Question Answering
   * arXiv: https://www.aclweb.org/anthology/D19-1255.pdf  
   * Repo:  
   * Sum: 
   * Note:
   * Label: 阿里| ACL2019 | MS_MARCO | 

9. | Commonsense for Generative Multi-Hop Question Answering Tasks
   * arXiv: https://arxiv.org/pdf/1809.06309.pdf 
   * Repo: https://github.com/yicheng-w/CommonSenseMultiHopQA
   * Sum: 
   * Note:
   * Label: 20190701| EMNLP2018 | unc | multihop generative task (NarrativeQA) - WikihopQA  | 
10. K-Bert | K-BERT: Enabling Language Representation with Knowledge Graph  
   * arXiv: https://arxiv.org/pdf/1909.07606.pdf  
   * Repo:  https://github.com/autoliuweijie/K-BERT  
   * Sum: 不用总结了 
   * Note:
   * Label: AAAI2020 | 腾讯*北大 | 
11. | Knowledge Infused Learning (K-IL): Towards Deep Incorporation of Knowledge in Deep Learning  
   * arXiv: https://arxiv.org/pdf/1912.00512.pdf 
   * Repo:  
   * Sum: 
   * Note:
   * Label:  
12. SKG | Machine Reading Comprehension Using Structural Knowledge Graph-aware Network  
   * arXiv: https://www.aclweb.org/anthology/D19-1602.pdf   
   * Repo:  
   * Sum: 
   * Note:
   * Label: qdl | EMNLP2019-Short | Sota-ReCoRD   
13. KAR | Explicit Utilization of General Knowledge in Machine Reading Comprehen  
   * arXiv: https://arxiv.org/pdf/1809.03449.pdf  
   * Repo:  
   * Sum: 知识辅助增强的阅读理解 
   * Note:
   * Label: 20190520 | SQuAD | WortNet   
14. | Graph-Based Reasoning over Heterogeneous External Knowledge for Commonsense Question Answering
   * arXiv: https://arxiv.org/pdf/1909.05311.pdf  
   * Repo:  
   * Sum: 
   * Note:
   * Label:20190909 | 微软*北大 *信工所 | CommonSenseQA   
15.Cos-E 、CAGE | Explain Yourself! Leveraging Language Models for Commonsense Reasoning 
   * arXiv: https://www.aclweb.org/anthology/P19-1487.pdf 
   * Repo: https://github.com/nazneenrajani/CoS-E 
   * Sum: 
   * Note:
   * Label: acl2019 | CommonSenseQA | salesforce 
16. Taxonomical hierarchy of canonicalized relations from multiple
   * arXiv: https://arxiv.org/pdf/1909.06249.pdf  
   * Repo: https://github.com/akshayparakh25/relationhierarchy
   * Sum: 融合不同来源的知识，统一格式  
   * Note: 
   * Label: 20191112 | DBPedia-Wikidata | 
17. KAAS | Knowledge-Enhanced Attentive Learning for Answer Selection in Community Question Answering Systems   
   * arXiv: https://arxiv.org/abs/1912.07915 
   * Repo:  https://sites.google.com/view/jingfengshi/home/blog/code 
   * Sum: 
   * Note:
   * Label:  *** 
18. KRL | Integrating Graph Contextualized Knowledge into Pre-trained Language Models
   * arXiv: https://arxiv.org/pdf/1912.00147.pdf   
   * Repo:  
   * Sum: 
   * Note:
   * Label: 华为*中科院 | 20191203 | 和TransE比较 |   K-Bert的另一种变体  
19. Commonsense Reasoning Using WordNet and SUMO: a Detailed Analysis  
   * arXiv: https://arxiv.org/pdf/1909.02314.pdf  
   * Repo:  
   * Sum: 
   * Note:
   * Label: 20190906 | commonsense推理的分析 | 
20. 常识性推理综述 | Recent Advances in Natural Language Inference: A Survey of Benchmarks, Resources, and Approaches  
    * 第一次名字: Commonsense Reasoning for Natural language understanding : A survey of Benchmarks,Resources, and Approaches. 
  
   * arXiv:  https://arxiv.org/pdf/1904.01172.pdf  
   * Repo:  
   * Sum: 
   * Note:
   * Label: NLI-NLU-Reasoning的综述 

22. Everything Happens for a Reason: Discovering the Purpose of Actions in Procedural Text 
   * arXiv:  https://arxiv.org/pdf/1909.04745.pdf  
   * Repo:  
   * Sum: 
   * Note:
   * Label:  ProPara数据集 
23. | Can a Gorilla Ride a Camel? Learning Semantic Plausibility from Text
   * arXiv:   https://arxiv.org/pdf/1911.05689.pdf 
   * Repo:  
   * Sum: 
   * Note:
   * Label: 从文章中构建语义相似关系，用于常识推理
24. | Event Representation Learning Enhanced with External Commonsense Knowledge  
   * arXiv:   https://arxiv.org/pdf/1909.05190.pdf  
   * Repo:  https://github.com/MagiaSN/CommonsenseERL
   * Sum:事件表示中 加入 情绪、情感等外部知识增强 事件表示，在三种事件相关数据集取得好的性能.  
   * Note:
   * Label:  
25. SenMaking-and-Explanation 数据集| Does It Make Sense? And Why? A Pilot Study for Sense Making and Explanation
   * arXiv:   https://arxiv.org/pdf/1906.00363.pdf
   * Repo:  https://github.com/wangcunxiang/SenMaking-and-Explanation
   * Sum:对于常识检测以前方法都是简介的检测，文章提出新的数据集，直接检测模型对于常识的识别能力: 给定一对pair陈述，判断哪个陈述是正确的，符合常识的，然后对于错误的一个句子，再进一步选择 为什么错，作为explation 
   * Note:
   * Label:  
26. AHE | Alignment over Heterogeneous Embeddings for Question Answering 
   * arXiv:   https://www.aclweb.org/anthology/N19-1274.pdf
   * Repo:  https://github.com/vikas95/AHE 
   * Sum:将问题和候选答案  中  每个单词与检索到的支持段落中 最相似的单词对齐，并将 每个对齐分数与相应的 问题/答案 术语的文档频率倒数进行权衡。   
   * Note:
   * Label: ARC数据集 |  多知识源、多种embedding融合的方式问题等等。  
27. | Commonsense Reasoning Using WordNet and SUMO: a Detailed Analysis
   * arXiv: https://arxiv.org/pdf/1909.02314.pdf  
   * Repo:  
   * Sum: 评估常识推理基准以及常识推理涉及的  知识资源的质量 ，分析现在常识知识库使用过程中存在的问题
   * Note:
   * Label:  
28. | Question Answering over Knowledge Graphs via Structural Query Patterns 
   * arXiv:   https://arxiv.org/pdf/1910.09760.pdf 
   * Repo:  
   * Sum: KBQA：KBQA 中总结问题的模式，代替parsing 
   * Note:
   * Label:  
29.  | Dynamic Knowledge Graph Construction for Zero-shot Commonsense Question Answering
   * arXiv:   
   * Repo:  
   * Sum: 理解叙事文本需要对 文本中描述的情况、状态、影响进行 推理，这又要求社会常识，难点: 如何让根据上下文选择相关知识并进行推理。  本文对于 zero-shot常识将任务转化未 动态生成的常识图上的概率推理。   --> 一种使用上下结合 COMET 文生成常识的方法; 
   * Note:
   * Label:  Social IQA  | StoryCommonSense 数据集| 20191110
30. d | Towards Generalizable Neuro-Symbolic Systems for Commonsense Question Answering 
   * arXiv: https://arxiv.org/pdf/1910.14087.pdf
   * Repo:  
   * Sum: 对于现有的融合知识的方法进行研究和总结 
   * Note:
   * Label:  
31. COMET | Commonsense Knowledge Base Completion with Structural and Semantic Context
   * arXiv:   https://arxiv.org/pdf/1910.02915.pdf
   * Repo: github.com/allenai/commonsense-kg-completion 
   * Sum: 一种知识库自动生成、自动补全的方法，自动生成知识图谱
   * Note:https://blog.csdn.net/sinat_34611224/article/details/94604097  
   * Label:  ACL2019 | AI2 | 
32. Models | LEARNING TO RETRIEVE REASONING PATHS OVER WIKIPEDIA GRAPH FOR QUESTION ANSWERING
   * arXiv: https://arxiv.org/pdf/1911.10470.pdf
   * Repo:  
   * Sum: 递归检索学习 推理路径，回答开放域  多跳 问题
   * Note:
   * Label: AI2 | 20191104 | 
33. d | Generative Adversarial Zero-Shot Relational Learning for Knowledge Graphs
   * arXiv:   
   * Repo:  
   * Sum: 通过GAN学习知识库中的 zero-shot 关系的学习和补全 
   * Note:
   * Label: UCSB-王威廉 | 20200108  |  
34. d  
   * arXiv:   
   * Repo:  
   * Sum: 
   * Note:
   * Label:  
35. d  
   * arXiv:   
   * Repo:  
   * Sum: 
   * Note:
   * Label:  
36. d  
   * arXiv:   
   * Repo:  
   * Sum: 
   * Note:
   * Label:  
37. d  
   * arXiv:   
   * Repo:  
   * Sum: 
   * Note:
   * Label:  
38. d  
   * arXiv:   
   * Repo:  
   * Sum: 
   * Note:
   * Label:  
39. d  
   * arXiv:   
   * Repo:  
   * Sum: 
   * Note:
   * Label:  
40. d  
   * arXiv:   
   * Repo:  
   * Sum: 
   * Note:
   * Label:  
41. d  
   * arXiv:   
   * Repo:  
   * Sum: 
   * Note:
   * Label:  
42. d  
   * arXiv:   
   * Repo:  
   * Sum: 
   * Note:
   * Label:  
43. d  
   * arXiv:   
   * Repo:  
   * Sum: 
   * Note:
   * Label:  
44. d  
   * arXiv:   
   * Repo:  
   * Sum: 
   * Note:
   * Label:  
45. d  
   * arXiv:   
   * Repo:  
   * Sum: 
   * Note:
   * Label:  
46. d  
   * arXiv:   
   * Repo:  
   * Sum: 
   * Note:
   * Label:    
### Multi-hop QA  
1. PathNet | Exploiting Explicit Paths for Multi-hop Reading Comprehension   
   * arXiv:  https://arxiv.org/pdf/1811.01127.pdf   
   * Repo:  https://github.com/allenai/PathNet
   * Sum: 
   * Note:
   * Label: 新加坡国立*allenai |  OpenBookQA | 20190708   
### 常见知识库总结: 
1. ASER: A Large-scale Eventuality Knowledge Graph
    * arXiv:https://arxiv.org/pdf/1905.00270.pdf 
    * Repo: : https://github.com/HKUST-KnowComp/ASER 
    * Sum:  
    * Leadboard:
    * Label:  
2. Event2Mind: 
    * arXiv: https://arxiv.org/pdf/1805.06939.pdf
    * Leadboard/data:https://uwnlp.github.io/event2mind/    
    * Sum:  
    * Note: 
    * label:   
3. Atomic: ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning
    * arXiv: https://homes.cs.washington.edu/~msap/atomic/data/sap2019atomic.pdf 
    * Leadboard/data: An ATlas Of MachIne Commonsense, https://homes.cs.washington.edu/˜msap/atomic/.
    * Sum: 
    * Note:
    * Label: 
4. Does It Make Sense? And Why? A Pilot Study for Sense Making and Explanation
    * arXiv: https://arxiv.org/pdf/1906.00363.pdf
    * Leadboard/data: https://github.com/wangcunxiang/Sen-Making-and-Explanation 
    * Sum: 设计一个数据集直接测试模型对于 常识的感知能力，并对于原因进行测试 。  eg: 1. 大象放进冰箱 vs 火鸡放进冰箱  哪一个是正确的。 2. 为什么？ 1) 2) 3) 
    * Note:
    * Label: 



### AAAI 2020  
Reading: 14/15   comprehension : ADD+ 0 
1. ReCO: A Large Scale Chinese Reading Comprehension Dataset on Opinion [未公布] 
2. DCMN+: Dual Co-Matching Network for Multi-choice Reading Comprehension 
* https://arxiv.org/pdf/1908.11511.pdf  新改了 20200116
3. Unsupervised Domain Adaptation on Reading Comprehension 
4. Generating Well-formed Answers by Machine Reading with Stochastic Selector Networks 
5. A Robust Adversarial Training Approach to Machine Reading Comprehension
6. TextScanner: Reading Characters in Order for Robust Scene Text Recognition
7. SG-Net: Syntax-Guided Machine Reading Comprehension
8. Multi-Task Learning with Generative Adversarial Training for Multi-Passage Machine Reading
Comprehension
9. Multi-Task Learning with Generative Adversarial Training for Multi-Passage Machine Reading
Comprehension
10. MMM: Multi-stage Multi-task Learning for Multi-choice Reading Comprehension  
11.  Co-Attention Hierarchical Network: Generating Coherent Long Distractors for Reading Comprehension 
* https://arxiv.org/pdf/1911.08648.pdf  新版本 20191120 
12.Assessing the Benchmarking Capacity of Machine Reading Comprehension Datasets 
* https://arxiv.org/pdf/1911.09241.pdf 
13.  Translucent Answer Predictions in Multi-Hop Reading Comprehension  IBM 
14.   Select, Answer and Explain: Interpretable Multi-hop Reading Comprehension over Multiple Documents
* https://arxiv.org/pdf/1911.00484.pdf  20191122 

multi-hop 1/4 add 
1.   Knowledge Graph Alignment Network with Gated Multi-hop Neighborhood Aggregation  

reason 
1.Graph-Based Reasoning over Heterogeneous External Knowledge for Commonsense Question Answering   
2.  Differentiable Reasoning on Large Knowledge Bases and Natural Language 
https://arxiv.org/pdf/1912.10824.pdf

3. Coordinated Reasoning for Cross-Lingual Knowledge Graph Alignment 
4. PIQA: Reasoning about Physical Commonsense in Natural Language  数据集   

Question
1.  An Empirical Study of Content Understanding in Conversational Question Answering 公布 
2.   Improving Knowledge-aware Dialogue Generation via Knowledge Base Question Answering 公布 
3.   Asking the Right Questions to the Right Users: Active Learning with Imperfect Oracles  
4.   JEC-QA: A Legal-Domain Question Answering Dataset 数据集 -公布  THU 
5.   Iteratively Questioning and Answering for Interpretable Legal Judgment Prediction  THU 
6.    Knowledge and Cross-Pair Pattern Guided Semantic Matching for Question Answering 
7.    Neural Question Generation with Answer Pivot  
8.    Getting Closer to AI Complete Question Answering: A Set of Prerequisite Real Tasks 
9.    QASC: A Dataset for Question Answering via Sentence Composition  |  AI2 
https://arxiv.org/pdf/1910.11473.pdf  


Answering: 
1. Hashing based Answer Selection  
2. Capturing Sentence Relations for Answer Sentence Selection with Multi-Perspective Graph Encoding    TZX 
3. Hypothetical Answers to Continuous Queries over Data Streams  
4. Joint Learning of Answer Selection and Answer Summary Generation in Community Question Answering  亚马逊
5. 