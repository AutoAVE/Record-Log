# paper list 
## 阅读理解    
![MRC_概览](./../../Record-logger/图片/00045_MRC整理总览_ZT.png)  
![MRC_示意图](./../../Record-Logger/图片/00044_MRC背景总结_ZT.png)  
![MRC_数据集](./../../Record-Logger/图片/00043_MRC数据集整理_ZT.png)  
## Bert @ Pre-Trained  

## MRC综述: 
* 陈丹绮博士论文: 
  * 论文地址:   
  *  别人笔记: 
  * 自己笔记: 
* 王炳宁博士论文:
  * 论文地址: 
  * 自己笔记:  
* 吴明昊博士论文:
  * 论文地址: 
  * 自己笔记:   
* 国防科大综述:
  * 论文地址: 
  * 笔记:  
* UCAS综述:
  * 论文地址: 
  * 笔记:  
* 推理综述:
  * 论文地址: 
  * 笔记:   

### 数据集系列文章: 
* 2013-MCTest : 
  * 论文地址: 
  * 笔记: 
  *  
* 2015-CNN/Daily Mail：
* 2016-SQuAD ：   

## GNN  

## Bert-预训练  

## 其他任务   
## 大的实验室: 
1. UCL MRC_Group: 
2. AI2: 
3. 微软:
4. THU:
5. PKU:

## **数据集文章**    
### MRC
1. **ROPES** |  Reasoning Over Paragraph Effects in Situations  
   * arXiv: https://arxiv.org/abs/1908.05852 
   * Leadboard: https://leaderboard.allenai.org/ropes
   * Note
   * Label: EMNLP2019 
2. .CommonSenseQA |COMMONSENSEQA: A Question Answering Challenge Targeting Commonsense Knowledge | 
   * arXiv: https://arxiv.org/pdf/1811.00937.pdf |  
   * Leadboard: https://www.tau-nlp.org/csqa-leaderboard 
   * Note:
   * Label: 2018 
3. CoQA |  CoQA: A Conversational Question Answering Challenge 
   * arXiv: https://arxiv.org/pdf/1808.07042.pdf 
   * Leadboard:https://stanfordnlp.github.io/coqa/ 
   * Note:
   * Label: 2018 
4. MultiRC | Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences
    * ACL: https://www.aclweb.org/anthology/N18-1023/   
   * Leadboard: https://cogcomp.seas.upenn.edu/multirc/ 
    * Note: 
    * Label: NAACL2018 
5. OpenBookQA | Can a Suit of Armor Conduct Electricity?  A New Dataset for Open Book Question Answering
   * arXiv: https://arxiv.org/pdf/1809.02789.pdf  
   * Leadboard: 
   * Note:
   * Label: 201809
6. RACE  |  RACE: Large-scale ReAding Comprehension Dataset From Examinations
   * arXiv: https://arxiv.org/pdf/1704.04683.pdf 
   * Leadboard: http://www.qizhexie.com//data/RACE_leaderboard 
   * Note:
   * Label: 201809
7. XCMRC  |  XCMRC: Evaluating Cross-lingual Machine Reading Comprehension

      * arXiv: https://arxiv.org/pdf/1908.05416.pdf 
   * Leadboard/baseline: https://github.com/NLPBLCU/XCMRC
   * Note:
   * Label: 跨语言 | 20190825  
8. CLMRC  |  Cross-Lingual Machine Reading Comprehension 
    * arXiv: https://arxiv.org/pdf/1909.00361.pdf 
   * Leadboard/baseline: https://github.com/ymcui/Cross-Lingual-MRC
   * Note:
   * Label: 跨语言 
9.  WINOGRANDE  |  WINOGRANDE: An Adversarial Winograd Schema Challenge at Scale  
    * arXiv: https://arxiv.org/pdf/1907.10641.pdf
    * Leadboard: 
    * Note:
    * Label:  201911 
11. HellaSwag  |  HellaSwag: Can a Machine Really Finish Your Sentence?  
    * arXiv: https://arxiv.org/pdf/1905.07830.pdf    
    * Leadboard: https://rowanzellers.com/hellaswag/  
    * Note:
    * Label:  201905  
12. McTaco  |  “Going on a vacation” takes longer than “Going for a walk”: A Study of Temporal Commonsense Understanding

    * arXiv: https://arxiv.org/pdf/1909.03065.pdf
    * Leadboard: https://leaderboard.allenai.org/mctaco/submissions/public 
    * Note:
    * Label:  EMNLP2019 | ai2
13. Social IQA  | SOCIAL IQA: Commonsense Reasoning about Social Interactions    
    * arXiv: https://arxiv.org/pdf/1904.09728.pdf 
    * Leadboard: https://leaderboard.allenai.org/socialiqa/submissions/public
    * Note:
    * Label:  2019 
14. CosMosQA  |  Cosmos QA : Machine Reading Comprehension with Contextual Commonsense  Reasoning (EMNLP'2019)   
    * arXiv: https://arxiv.org/pdf/1909.00277.pdf
    * Leadboard: https://wilburone.github.io/cosmos/
    * Note:
    * Label: emnlp2019 
15. PubMedQA |  PubMedQA : A Dataset for Biomedical Research Question Answering
    * arXiv: https://arxiv.org/pdf/1909.06146.pdf  
    * Leadboard: https://pubmedqa.github.io 
    * Note:
    * Label: 2019009  
16. GeoQA  | GeoSQA: A Benchmark for Scenario-based Question Answering in the Geography   Domain at High School Level   
    * arXiv: https://arxiv.org/pdf/1908.07855.pdf  
    * Leadboard: 
    * Note:
    * Label:  emnlp2019 
17.  HEAD-QA |  HEAD-QA: A Healthcare Dataset for Complex Reasoning
     * arXiv: https://arxiv.org/abs/1906.04701 
     * Leadboard: 
     * Note:
     * Label: 2019  
18. ReCoRD | ReCoRD: Bridging the Gap between Human and Machine Commonsense Reading Comprehension  
    * arXiv: https://arxiv.org/pdf/1810.12885.pdf  
    * Leadboard: https://sheng-z.github.io/ReCoRD-explorer/  
    * Note:
    * Label: 2018     
19. c^3 |  Investigating Prior Knowledge for Challenging Chinese Machine Reading Comprehension 
    * arXiv: https://arxiv.org/pdf/1904.09679.pdf
    * Leadboard/Baseline : https://dataset.org/c3/  |   https://github.com/AutoAVE/c3  
    * Note:
    * Label:  2019 | 腾讯、Cornell、UW、AI2 
20. Dream |  DREAM: A Challenge Dataset and Models for Dialogue-Based Reading Comprehension
    * arXiv: https://arxiv.org/pdf/1902.00164.pdf 
    * Leadboard: https://dataset.org/dream/
    * Note:
    * Label:2019 | 腾讯、Cornell、UW、AI2 
21. QAngaroo 、WikihopQA |   Constructing Datasets for Multi-hop Reading Comprehension  Across Documents

    * arXiv: https://arxiv.org/pdf/1710.06481v1.pdf  
    * Leadboard: http://qangaroo.cs.ucl.ac.uk/  
    * Note:
    * Label: Multi-hop 
22. JEC-QA | JEC-QA: A Legal-Domain Question Answering Dataset  
    * arXiv: https://arxiv.org/pdf/1911.12011.pdf
    * Leadboard/baseline: http://jecqa.thunlp.org/ 
    * Note:
    * Label:
23. PIQA | PIQA: Reasoning about Physical Commonsense in Natural Language   
    * arXiv: https://arxiv.org/pdf/1911.11641.pdf  
    * Leadboard: https://yonatanbisk.com/piqa/
    * Note:
    * Label:
24. TweetQA | TWEETQA: A Social Media Focused Question Answering Dataset  
    * arXiv: https://arxiv.org/pdf/1907.06292.pdf
    * Leadboard: https://tweetqa.github.io/
    * Note:
    * Label:
25. RC-QED | RC-QED: Evaluating Natural Language Derivations in Multi-Hop Reading Comprehension   
    * arXiv: https://arxiv.org/pdf/1910.04601.pdf 
    * Leadboard/baseline/data:https://naoya-i.github.io/rc-qed/  
    * Note:
    * Label:
26. MLQA | MLQA: Evaluating Cross-lingual Extractive Question Answering  
    * arXiv: https://arxiv.org/pdf/1910.07475.pdf 
    * Leadboard/baseline:https://github.com/facebookresearch/MLQA  
    * Note:
    * Label: 跨语言 
27. QuAC| QuAC : Question Answering in Context  
    * arXiv: https://arxiv.org/pdf/1808.07036.pdf
    * Leadboard: http://quac.ai/
    * Note:
    * Label:
28. CNN/Daily-Mail  |  Challenging Reading Comprehension on Daily Conversation: Passage Completion on Multiparty Dialog  
    * arXiv/acl:https://www.aclweb.org/anthology/N18-1185/  
    * Leadboard/baseline:https://github.com/danqi/rc-cnn-dailymail  
    * Note:
    * Label:
29. 谷歌acl2019医疗对话数据集| Extracting Symptoms and their Status from Clinical Conversations   
    * arXiv:https://arxiv.org/pdf/1906.02239.pdf  
    * Leadboard: 未开源
    * Note:
    * Label:
30. NAACL2019医患对话数据集  | Fast Prototyping a Dialogue Comprehension System for Nurse-Patient Conversations on Symptom Monitoring
  
    * arXiv: https://arxiv.org/pdf/1903.03530.pdf
    * Leadboard: 未开源
    * Note:
    * Label:
31. DROP |  DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs  
    * arXiv: https://arxiv.org/pdf/1903.00161v1.pdf
    * Leadboard: https://leaderboard.allenai.org/drop/submissions/public
    * Note:
    * Label:
32. HotpotQA | HOTPOTQA: A Dataset for Diverse, Explainable Multi-hop Question Answering
    * arXiv: https://arxiv.org/pdf/1809.09600.pdf
    * Leadboard: https://hotpotqa.github.io/ 
    * Note:
    * Label:
33. QuoRef | QUOREF: A Reading Comprehension Dataset with Questions Requiring Coreferential Reasoning
    * arXiv: https://arxiv.org/pdf/1908.05803.pdf 
    * Leadboard: https://leaderboard.allenai.org/quoref/submissions/public 
    * Note:
    * Label:

34. Multi-QA | MULTIQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension 
    * arXiv: https://arxiv.org/pdf/1905.13453.pdf
    * Leadboard: 
    * Note:
    * Label: 多个数据集合成
35. MRQA2019| MRQA 2019 Shared Task: Evaluating Generalization in Reading Comprehension
    * arXiv: https://arxiv.org/pdf/1910.09753.pdf 
    * Leadboard/baseline: https://github.com/mrqa/MRQA-Shared-Task-2019  
    * Note:
    * Label:多个数据集合成
36. ATOMIC | ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning 
    * arXiv: https://homes.cs.washington.edu/~msap/atomic/data/sap2019atomic.pdf  
    * Leadboard/data: https://homes.cs.washington.edu/˜msap/atomic/.
    * Note:
    * Label:外部知识库 数据集 
37. ORB | ORB: An Open Reading Benchmark for Comprehensive Evaluation of Machine Reading Comprehension
    * arXiv: https://arxiv.org/abs/1912.12598
    * Leadboard: https://leaderboard.allenai.org/orb/submissions/public 
    * Note:
    * Label: 多数据集合成 
38. ACL2019做对话同时发布数据集| Conversing by Reading: Contentful Neural Conversation with On-demand Machine Reading
    * arXiv/ACL: https://www.aclweb.org/anthology/P19-1539.pdf
    * Leadboard/baseline: https://github.com/qkaren/converse_reading_cmr
    * Note:
    * Label:Wikipedia文章+Reddit对话 --> 数据集 | ACL2019 | 数据集
39. emrQA | emrQA: A Large Corpus for Question Answering on Electronic Medical Records 
    * arXiv: https://arxiv.org/pdf/1809.00732.pdf
    * Leadboard/Baseline: https://github.com/panushri25/emrQA
    * Note:
    * Label:
40. ComQA | ComQA: A Community-sourced Dataset for Complex Factoid Question Answering with Paraphrase Clusters
    * arXiv: https://arxiv.org/abs/1809.09528
    * Leadboard: 
    * Note:
    * Label:社区问答数据集
41. ConvQuestions |  Look before you Hop: Conversational Question Answering over Knowledge Graphs Using Judicious Context Expansion
    * arXiv: https://arxiv.org/pdf/1910.03262.pdf
    * Leadboard: http://qa.mpi-inf.mpg.de/convex/  
    * Note:
    * Label: cikm2019 
42. ShARC(Shaping Answers with Rules through Conversation) |  Interpretation of Natural Language Rules in Conversational Machine Reading
    * arXiv: https://arxiv.org/pdf/1809.01494.pdf 
    * Leadboard: https://sharc-data.github.io/  
    * Note:
    * Label: UCL_MRC_Grouping |  
43. DuoRC | DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension
    * arXiv: https://arxiv.org/pdf/1804.07927.pdf 
    * Leadboard: https://duorc.github.io/  
    * Note:
    * Label: 2018    
44. MCScript|  MCScript: A Novel Dataset for Assessing Machine Comprehension Using Script Knowledge 
    * arXiv:https://arxiv.org/abs/1803.05223
    * Leadboard:  
    * Note:  
    * Label: 
45. SQuAD2.0 | Know What You Don’t Know: Unanswerable Questions for SQuAD 
    * arXiv: https://arxiv.org/pdf/1806.03822.pdf  
    * Leadboard:https://rajpurkar.github.io/SQuAD-explorer/    
    * Note:  
    * Label: 
46. RecipeQA |  RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes 
    * arXiv:https://arxiv.org/pdf/1809.00812.pdf 
    * Leadboard:  https://hucvl.github.io/recipeqa/  
    * Note:  
    * Label: 
47. SWAG |  SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference 
    * arXiv: https://arxiv.org/abs/1808.05326
    * Leadboard: https://leaderboard.allenai.org/swag/submissions/public 
    * Note:  
    * Label: 
48. TextWordsQA | Multi-Relational Question Answering from Narratives: Machine Reading and Reasoning in Simulated Worlds   
    * arXiv/ACL:https://www.aclweb.org/anthology/P18-1077.pdf
    * Leadboard:  https://igorlabutov.github.io/textworldsqa.github.io/  
    * Note:  
    * Label: 
49. CLOTH | Large-scale Cloze Test Dataset Created by Teachers  
    * arXiv: https://arxiv.org/abs/1711.03225
    * Leadboard: http://www.qizhexie.com/data/CLOTH_leaderboard.html
    * Note:  
    * Label: 2017 
50. CLiCR  | CliCR: A Dataset of Clinical Case Reports for Machine Reading Comprehension
    * arXiv: https://arxiv.org/abs/1803.09720
    * Leadboard/Baseline: https://github.com/clips/clicr 
    * Note:  
    * Label: 2018 
51. DuReader | DuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications 
    * arXiv:https://arxiv.org/abs/1711.05073 
    * Leadboard/baseline:https://github.com/baidu/DuReader    
    * Note:  
    * Label: 中文 2017 
52. NarrativeQA | The NarrativeQA Reading Comprehension Challenge    
    * arXiv:https://arxiv.org/abs/1712.07040 
    * Leadboard:  
    * Note:  
    * Label: google 2017 
53. Who did What | Who did What: A Large-Scale Person-Centered Cloze Dataset
    * arXiv: https://arxiv.org/abs/1608.05457 
    * Leadboard:  https://tticnlp.github.io/who_did_what/leaderBoard.html  
    * Note:  
    * Label: 2017 
54. SearchQA | SearchQA: A New Q&A Dataset
Augmented with Context from a Search Engine  
    * arXiv: https://arxiv.org/pdf/1704.05179.pdf  
    * Leadboard/baseline: https://github.com/nyu-dl/dl4ir-searchqA   
    * Note:  
    * Label: 2017  
45. TriviaQA | TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension  
    * arXiv:https://arxiv.org/abs/1705.03551 
    * Leadboard/baseline:  http://nlp.cs.washington.edu/triviaqa/  
    * Note:  
    * Label: 2017
50. Quasar| Quasar: Datasets for Question Answering by Search and Reading    
    * arXiv:https://arxiv.org/abs/1707.03904 
    * Leadboard/baseline: https://github.com/bdhingra/quasar   
    * Note:  
    * Label: 2017 
50. bAbi |  TOWARDS AI-COMPLETE QUESTION ANSWERING: A SET OF PREREQUISITE TOY TASKS
    * arXiv:https://arxiv.org/pdf/1502.05698.pdf
    * Leadboard:  https://github.com/facebook/bAbI-tasks 
    * Note: CBT
    * Label: 2015 
50. CBT(Children's Books Tests) | The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations  
    * arXiv:https://arxiv.org/abs/1511.02301 
    * Leadboard:  
    * Note:  
    * Label: bAbi 
50. MS_MARCO | MS MARCO: A Human Generated MAchine Reading COmprehension Dataset
    * arXiv:https://arxiv.org/pdf/1611.09268.pdf 
    * Leadboard:  http://www.msmarco.org/leaders.aspx 
    * Note:  
    * Label: 2018 
50. NewsQA | NewsQA: A Machine Comprehension Dataset
    * arXiv:https://arxiv.org/abs/1611.09830 
    * Leadboard: https://www.microsoft.com/en-us/research/project/newsqa-dataset/  
    * Note:  
    * Label: 2017 
50. LAMBADA | The LAMBADA dataset: Word prediction requiring a broad discourse context
    * arXiv: https://arxiv.org/abs/1606.06031 
    * Leadboard:  
    * Note:  
    * Label: 2016 
50. SCT(Story Cloze Test) |  A Corpus and Evaluation Framework for Deeper Understanding of Commonsense Stories  
    * arXiv:https://arxiv.org/abs/1604.01696 
    * Leadboard/Baseline: https://www.cs.rochester.edu/nlp/rocstories/ 
    * Note:  
    * Label: 
50. sd  
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
50. sd  
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
50. sd  
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
50. sd  
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
50. sd  
    * arXiv:
    * Leadboard:  
    * Note:  
    * Label: 
### 模型文章 ---QA & MRC    
#### 1. BiDAF | 
* arXiv:
* Repo:
* Note:
* Label: 
#### 2.. QANet |   
* arXiv:
* Repo:
* Note:
* Label: 

## 模型 & 分析 --Bert @ Pre-Trained Model ans Analyze 
1. Bert |  
    * arXiv:  
    * Repo:
    * Note:
    * Label: 
2. ALBert |  ALBERT: A LITE BERT FOR SELF-SUPERVISED
LEARNING OF LANGUAGE REPRESENTATIONS 
    * arXiv:  https://openreview.net/pdf?id=H1eA7AEtvS 
    * Repo:
    * Note:
    * Label: 
3. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
4. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
5. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
6. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
7. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
8. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
9. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
10. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
11. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
12. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
13. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
14. Bert |  
    * arXiv:
    * Repo:  
    * Note:
    * Label: 
